import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.linear_model import LinearRegression
import numpy as np
import koreanize_matplotlib
from matplotlib.patches import Patch

# adjustText ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: í„°ë¯¸ë„ì—ì„œ 'pip install adjustText'
from adjustText import adjust_text

st.set_page_config(page_title="ë°©ë¬¸ììˆ˜Â·ë¬¸í™”ìì›ìˆ˜ ë„/ê´‘ì—­ì‹œë³„ ì‹œê°í™”", layout="wide")
st.title("ğŸ“Š ê´‘ì—­ì§€ìì²´ë³„ ë°©ë¬¸ììˆ˜ & ë¬¸í™”ìì›ìˆ˜(ê·¼ëŒ€ë¬¸í™”ìœ ì‚°+ì¶•ì œ) ë¹„êµ")

# ======= 1. ë„/ê´‘ì—­ì‹œ í‘œì¤€ëª… ë§¤í•‘ =======
standard_names_map = {
    "ê°•ì›ë„": "ê°•ì›ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„": "ê°•ì›ë„",
    "ê²½ê¸°ë„": "ê²½ê¸°ë„",
    "ê²½ìƒë‚¨ë„": "ê²½ìƒë‚¨ë„",
    "ê²½ìƒë¶ë„": "ê²½ìƒë¶ë„",
    "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼ê´‘ì—­ì‹œ",
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
    "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „ê´‘ì—­ì‹œ",
    "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°ê´‘ì—­ì‹œ",
    "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸íŠ¹ë³„ì‹œ", "ì„œìš¸ì‹œ": "ì„œìš¸íŠ¹ë³„ì‹œ",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
    "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°ê´‘ì—­ì‹œ",
    "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œê´‘ì—­ì‹œ",
    "ì „ë¼ë‚¨ë„": "ì „ë¼ë‚¨ë„",
    "ì „ë¼ë¶ë„": "ì „ë¼ë¶ë„", "ì „ë¶íŠ¹ë³„ìì¹˜ë„": "ì „ë¼ë¶ë„",
    "ì œì£¼ë„": "ì œì£¼ë„", "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ì œì£¼ë„",
    "ì¶©ì²­ë‚¨ë„": "ì¶©ì²­ë‚¨ë„",
    "ì¶©ì²­ë¶ë„": "ì¶©ì²­ë¶ë„"
}
def standardize_province(name):
    if pd.isna(name):
        return None
    return standard_names_map.get(str(name).strip(), name)

# ======= 2. ê·¼ëŒ€ë¬¸í™”ìœ ì‚° ë°ì´í„° ì „ì²˜ë¦¬ =======
try:
    df_heritage = pd.read_csv("data/KF_AREA_CLTUR_MDRN_CLTUR_HRITG_DATA_LIST_202312.csv", encoding='utf-8')
except UnicodeDecodeError:
    df_heritage = pd.read_csv("data/KF_AREA_CLTUR_MDRN_CLTUR_HRITG_DATA_LIST_202312.csv", encoding='cp949')
df_heritage = df_heritage.dropna(subset=['CTPRVN_NM', 'CTLSTT_LA', 'CTLSTT_LO'])
df_heritage = df_heritage.drop_duplicates(subset=['CTLSTT_LA', 'CTLSTT_LO'], keep='first')
df_heritage["CTPRVN_NM_std"] = df_heritage["CTPRVN_NM"].apply(standardize_province)
heritage_count = df_heritage.groupby('CTPRVN_NM_std')['DATA_MANAGE_NO'].count()

# ======= 3. ì§€ì—­ë¬¸í™”ì¶•ì œ ë°ì´í„° ì „ì²˜ë¦¬ =======
def extract_province(address):
    if pd.isna(address):
        return None
    return str(address).split()[0]
try:
    df_festival = pd.read_csv('data/ì „êµ­ë¬¸í™”ì¶•ì œí‘œì¤€ë°ì´í„°.csv', encoding='utf-8')
except UnicodeDecodeError:
    df_festival = pd.read_csv('data/ì „êµ­ë¬¸í™”ì¶•ì œí‘œì¤€ë°ì´í„°.csv', encoding='cp949')
df_festival = df_festival.dropna(subset=['ìœ„ë„', 'ê²½ë„'])
df_festival = df_festival[df_festival['ìœ„ë„'] != 0]
df_festival["ì‹œë„ëª…"] = df_festival["ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"].apply(extract_province)
df_festival["ì‹œë„ëª…_std"] = df_festival["ì‹œë„ëª…"].apply(standardize_province)
festival_count = df_festival.groupby('ì‹œë„ëª…_std')['ì¶•ì œëª…'].count()

# ======= 4. ë„/ê´‘ì—­ì‹œ ê¸°ì¤€ í†µí•© ì§‘ê³„ =======
all_regions = heritage_count.index.union(festival_count.index)
heritage_count_full = heritage_count.reindex(all_regions).fillna(0)
festival_count_full = festival_count.reindex(all_regions).fillna(0)
cultural_resources = heritage_count_full + festival_count_full
df_resources = pd.DataFrame({
    "ê´‘ì—­ì§€ìì²´ëª…": all_regions,
    "ê·¼ëŒ€ë¬¸í™”ìœ ì‚° ìˆ˜": heritage_count_full.values,
    "ì§€ì—­ì¶•ì œ ìˆ˜": festival_count_full.values,
    "ë¬¸í™”ìì›ìˆ˜": cultural_resources.values
}).reset_index(drop=True)

# ======= 5. ë°©ë¬¸ì ë°ì´í„° ì „ì²˜ë¦¬/í‘œì¤€í™” =======
try:
    df_visitors = pd.read_csv("data/ê´‘ì—­ë³„ë°©ë¬¸ììˆ˜.csv", encoding='utf-8')
except UnicodeDecodeError:
    df_visitors = pd.read_csv("data/ê´‘ì—­ë³„ë°©ë¬¸ììˆ˜.csv", encoding='cp949')
df_visitors["ê´‘ì—­ì§€ìì²´ëª…_std"] = df_visitors["ê´‘ì—­ì§€ìì²´ëª…"].apply(standardize_province)
if "ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜" in df_visitors.columns:
    df_visitors_unique = df_visitors[['ê´‘ì—­ì§€ìì²´ëª…_std', 'ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜']].drop_duplicates(subset=['ê´‘ì—­ì§€ìì²´ëª…_std'])
else:
    df_visitors_unique = df_visitors.groupby('ê´‘ì—­ì§€ìì²´ëª…_std')['ê¸°ì´ˆì§€ìì²´ ë°©ë¬¸ì ìˆ˜'].sum().reset_index()
    df_visitors_unique = df_visitors_unique.rename(columns={'ê¸°ì´ˆì§€ìì²´ ë°©ë¬¸ì ìˆ˜': 'ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜'})

# ======= 6. ë°ì´í„° ë³‘í•© =======
df = pd.merge(df_resources, df_visitors_unique, left_on="ê´‘ì—­ì§€ìì²´ëª…", right_on="ê´‘ì—­ì§€ìì²´ëª…_std", how="inner")

# ======= 1ï¸âƒ£ ì‚°ì ë„ - adjustText í™œìš© =======
st.header("1ï¸âƒ£ ì‚°ì ë„: ë¬¸í™”ìì›ìˆ˜(ê·¼ëŒ€ë¬¸í™”ìœ ì‚°+ì¶•ì œ) vs ë°©ë¬¸ììˆ˜")
fig, ax = plt.subplots(figsize=(8, 6))
sns.scatterplot(data=df, x="ë¬¸í™”ìì›ìˆ˜", y="ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜", s=90, ax=ax)
X = df["ë¬¸í™”ìì›ìˆ˜"].values.reshape(-1, 1)
y = df["ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜"].values
model = LinearRegression().fit(X, y)
x_vals = np.linspace(df["ë¬¸í™”ìì›ìˆ˜"].min(), df["ë¬¸í™”ìì›ìˆ˜"].max(), 100)
y_vals = model.predict(x_vals.reshape(-1, 1))
ax.plot(x_vals, y_vals, color="red", linestyle="--", label="íšŒê·€ì„ ")
# ë¼ë²¨ ê²¹ì¹¨ ë°©ì§€: adjustText ì‚¬ìš©
texts = []
for i, row in df.iterrows():
    texts.append(
        ax.text(row["ë¬¸í™”ìì›ìˆ˜"], row["ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜"], row["ê´‘ì—­ì§€ìì²´ëª…"], fontsize=9)
    )
adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle="-", color='gray', lw=0.5))

ax.set_xlabel("ë¬¸í™”ìì› ìˆ˜ (ê·¼ëŒ€ë¬¸í™”ìœ ì‚° + ì§€ì—­ì¶•ì œ ê°œìˆ˜)")
ax.set_ylabel("ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜")
ax.set_title("ë¬¸í™”ìì› ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë°©ë¬¸ììˆ˜ë„ ë§ë‹¤")
ax.legend()
st.pyplot(fig)

# ======= 2ï¸âƒ£ ë„/ê´‘ì—­ì‹œ ë‹¨ìœ„ ì´ì¤‘ yì¶• ë§‰ëŒ€ê·¸ë˜í”„ (ë²”ë¡€ ìƒ‰ìƒ Patch ì ìš©) =======
st.header("2ï¸âƒ£ ê´‘ì—­ì§€ìì²´ë³„ ë°©ë¬¸ììˆ˜ & ë¬¸í™”ìì›ìˆ˜ ì´ì¤‘ yì¶• ê·¸ë˜í”„")
df_sorted = df.sort_values("ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜", ascending=False).reset_index(drop=True)
bar_width = 0.45
x = np.arange(len(df_sorted))

fig2, ax1 = plt.subplots(figsize=(12, 7))
bars1 = ax1.bar(x - bar_width/2, df_sorted["ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜"], bar_width, label="ë°©ë¬¸ììˆ˜(ëª…)", color='tab:blue')
ax1.set_ylabel("ë°©ë¬¸ììˆ˜(ëª…)", color='tab:blue')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# ë‘ ë²ˆì§¸ yì¶• - ë¬¸í™”ìì›ìˆ˜ : ì •ê·œí™” (ìµœëŒ€ê°’ ê¸°ì¤€)
ax2 = ax1.twinx()
norm_cultural = df_sorted["ë¬¸í™”ìì›ìˆ˜"] / df_sorted["ë¬¸í™”ìì›ìˆ˜"].max() * df_sorted["ê´‘ì—­ì§€ìì²´ ë°©ë¬¸ì ìˆ˜"].max()
bars2 = ax2.bar(x + bar_width/2, norm_cultural, bar_width, label="ë¬¸í™”ìì›ìˆ˜ (ì •ê·œí™”)", color='tab:orange', alpha=0.7)
ax2.set_ylabel("ë¬¸í™”ìì›ìˆ˜ (ì •ê·œí™”, ìµœëŒ€ ë°©ë¬¸ììˆ˜ ê¸°ì¤€)", color='tab:orange')
ax2.tick_params(axis='y', labelcolor='tab:orange')

ax1.set_xticks(x)
ax1.set_xticklabels(df_sorted["ê´‘ì—­ì§€ìì²´ëª…"], rotation=45)
ax1.set_title("ê´‘ì—­ì§€ìì²´ë³„ ë°©ë¬¸ììˆ˜Â·ë¬¸í™”ìì›ìˆ˜ ì´ì¤‘ yì¶• ë¹„êµ")

# ë²”ë¡€(legend) íŒ¨ì¹˜ë¡œ ìƒ‰ìƒ ëª…í™•í•˜ê²Œ í‘œê¸°
legend_patches = [
    Patch(facecolor='tab:blue', label='ë°©ë¬¸ììˆ˜(ëª…)'),
    Patch(facecolor='tab:orange', label='ë¬¸í™”ìì›ìˆ˜ (ì •ê·œí™”)')
]
ax1.legend(handles=legend_patches, loc='upper right')

st.pyplot(fig2)

with st.expander("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(df)
